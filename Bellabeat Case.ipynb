{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Introduction\n\n","metadata":{}},{"cell_type":"markdown","source":"## How Can a Wellness Technology Company Play It Smart?","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Ask","metadata":{}},{"cell_type":"markdown","source":"### Background\n\nBellabeat\nis a high tech company that manufactures health focused smart products.They offer different\nsmart devices that collect data on activity, sleep, stress, and reproductive health to empower women\nwith knowledge about their own health and habits.\n\nThe main focus of this case is to analyze smart devices fitness data and determine how it could help\nunlock new growth opportunities for Bellabeat . We will focus on one of Bellabeat’s products: Bellabeat\napp.\n\nThe Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle,\nand mindfulness habits. This data can help users better understand their current habits and make\nhealthy decisions. The Bellabeat app connects to their line of smart wellness products.","metadata":{}},{"cell_type":"markdown","source":"### Key Stakeholders\n\n* Urška Sršen Bellabeat cofounder and Chief Creative Officer\n* Sando Mur Bellabeat cofounder and key member of Bellabeat executive team\n* Bellabeat Marketing Analytics team","metadata":{}},{"cell_type":"markdown","source":"### Bussiness Task\n\nGiven the previous facts, the business task is defined as searching for user patterns of usage of their\nsmart devices in order to gain insights that would later better orientate marketing decisions. So, in one\nphrase it would be:\n\nHow do our users use our smart devices?. Identify trends in how consumers use non\nBellabeat smart\ndevices to apply insights into Bellabeat’s marketing strategy.\n","metadata":{}},{"cell_type":"markdown","source":"# Step 2: Prepare","metadata":{}},{"cell_type":"markdown","source":"### Dataset used\n\nThe data source used for this case study is\nFitBit Fitness Tracker Data. This dataset is\nstored in Kaggle and was made available\nthrough Mobius and generated by\nrespondents to a distributed survey via\nAmazon Mechanical Turk between\n03.12.2016 05.12.2016.","metadata":{}},{"cell_type":"markdown","source":"### Accessibility and privacy of data\n\nThe data is licensed under CC0: Public\nDomain, waiving all of his or her rights to\nthe work worldwide under copyright law,\nincluding all related and neighboring rights,\nto the extend by law. The work can be\ncopied, modified, distributed and perform\nthe work, even for commercial purposes,\nall without asking permission","metadata":{}},{"cell_type":"markdown","source":"### Data organization and verification\n\nThe dataset is a collection of 18 .csv files.\n15 in long format, 3 in wide format. The\ndatasets consists of wide ranging\ninformation from activity metrics, calories,\nsleep records, metabolic equivalent of\ntasks (METs), heart rate and steps; in\ntimeframes of seconds, minutes, hours and\ndays","metadata":{}},{"cell_type":"markdown","source":"### Data limitations\n\nThe data has some limitations which could\nUndermine\nthe results of the analysis\nSuch\nlimitations to take into consideration\nare:\n* Missing demographics\n* Small simple size\n* Short time period of Data collection","metadata":{}},{"cell_type":"markdown","source":"# Step 3: Process","metadata":{}},{"cell_type":"markdown","source":"### Loading libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\n\nfrom pandas.api.types import CategoricalDtype\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing datasets","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, let's import the dataset 'dailyActivity_merged.csv' using the pandas pd.read_csv() function","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/fitbit/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data exploration\n\nOnce uploaded, let's firts see how many columns and rows we have, using the pandas function, .shape","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see, we have 940 rows and 15 columns. let's take a look at the names of the columns, using the .columns panda's function","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Knowing the names of the columns, let´s take a quick overview at the rows and the data itself, using the .head() pandas function","metadata":{}},{"cell_type":"code","source":"df.head(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset stores and tracks the data collected on a daily basis, by the FitBit Fitness tracking devices, such as smartwatches and/or fitness apps.\nFrom a quick view we can sumarize the columns as the following:\n* Id:                        is an unique identifier of the users in the survey\n* ActivityDate:              is the specific date of the entry\n* TotalSteps:                the total steps each user did each day\n* TotalDistance:             the total distance each user did each day\n* TrackerDistance:           is the distance the device tracked each day\n* LoggedActivitiesDistance:  is the distance tracked by the device on specific activities\n* VeryActiveDistance:        The distance traveled at a very active physical state?\n* ModeratelyActiveDistance:  The distance traveled at a moderately active physical state?\n* LightActiveDistance:       The distance traveled at a lightly active physical state?\n* SedentaryActiveDistance:   The distance traveled at a sedentary kind of active physical state?\n* VeryActiveMinutes:         The minutes spent at a very active physical state?\n* FairlyActiveMinutes:       The minutes spent at a fairly active physical state?\n* LightlyActiveMinutes:      The minutes spent at a lightly active physical state?\n* SedentaryMinutes:          The minutes spent at a lightly active physical state?\n* Calories:                  Calories burned that specific day","metadata":{}},{"cell_type":"markdown","source":"Once having a look a the columns and the data, we can star the proccess of cleaning","metadata":{}},{"cell_type":"markdown","source":"## Cleaning the data","metadata":{}},{"cell_type":"markdown","source":"### Checking Data types\n\nFirst we have to check if the data types align with the content and purpose of the data in each column, we can use the function .dtypes for that","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the Id columns is an integer, but it should be a string or object in this instance, why? because the Id is only an identifier, and our purpose is not to make mathematic operations with it, sums,multiplications, etc..\n\nAlso the ActivityDate columns is an object and should be a Date.\n\nOther than that all the other columns seem to be the correct data type","metadata":{}},{"cell_type":"code","source":"df['Id'] = df['Id'].astype(str)\ndf['ActivityDate'] = pd.to_datetime(df['ActivityDate'],format=\"%m/%d/%Y\")\ndf.dtypes # After reformating. We double check the data type","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we check the formats from before and we will convert the Id column from int to str using the .astype(str) function, and the 'ActivityDate' column from object or string, to datetime","metadata":{}},{"cell_type":"markdown","source":"### Checking column values\n\nAfter that we can get rid of columns that are not relevant for our analysis.\nFirst we note the 'TotalDistance' column, and the other columns related to distance tracking.\nWe see at first glance that 'TotalDistance' and 'Tracker Distance' have similar values, but we are not sure.\nWe also can assum that the 'TrackerDistance' or the 'TotalDistance' is the sum of the different \"*ActiveDistance\" columns, we may be wrong so we check first.","metadata":{}},{"cell_type":"code","source":"# We create a new column, adding up the \"ActiveDistance\" columns to see if it's equal to the 'TotalDistance' column, or the 'TrackerDistance' column\ndf['sum_distance'] = df['VeryActiveDistance'] + df['ModeratelyActiveDistance'] + df['LightActiveDistance'] + df['SedentaryActiveDistance']\n\n# We also notice that 'LoggedActivitiesDistance' have 0.0 in value in most entries, but we filter to find where has more than 0\ndf.loc[(df['LoggedActivitiesDistance'] > 0),['TotalDistance','TrackerDistance','LoggedActivitiesDistance','sum_distance']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The previous finding show that despite 'TotalDistance' and 'TrackerDistance' are not always 100% equal, they are the same in most cases.\nWe also see that there are entries in the 'LoggedActivitiesDistance' higher than 0, but are just a few.\nAnd finally we see that the sum of the 'ActiveDistance' columns is equal to the 'TotalDistance' column, only differing by 1 decimal due to rounding up.","metadata":{}},{"cell_type":"markdown","source":"So now, we have to decide if we want to keep all the columns, or deleting some, we conclude that the 'TotalDistance' column and the 'TotalDistance' are equal in most cases, (having the TotalDistance higher values). so we decide to keep 'TotalDistance'.\n\nAbout the 'ActiveDistance' columns, unfortunately we don't have an idea behind the categorization, what is the exact diffence between 'Moderately Active' and 'Very Active', maybe the heartbeat pulse at that moment?, steps per minute?, we don't know from this specific dataset, but we will keep them nonetheless.\n\nThe same could be said about the 'ActiveMinutes' columns, so we would just add them up in a new column","metadata":{}},{"cell_type":"code","source":"df['TotalMinutes'] = df['VeryActiveMinutes'] + df['FairlyActiveMinutes'] + df['LightlyActiveMinutes'] + df['SedentaryMinutes']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Renaming columns\n\nNow, let's rename the columns with the rename function.\nAnd also we want to turn them into lower case with the function str.lower()","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.lower()\ndf.rename(columns = {'trackerdistance':'tracker_distance','activitydate':'activity_date','totalsteps':'total_steps','totaldistance':'total_distance',\n       'loggedactivitiesdistance':'logged_activities_distance', 'veryactivedistance':'very_active_distance',\n       'moderatelyactivedistance':'moderately_active_distance', 'lightactivedistance':'light_active_distance',\n       'sedentaryactivedistance':'sedentary_active_distance', 'veryactiveminutes':'very_active_minutes',\n       'fairlyactiveminutes':'fairly_active_minutes','lightlyactiveminutes':'lightly_active_minutes',\n       'sedentaryminutes':'sedentary_minutes'}\n         ,inplace=True) # We make the changes permanent by using inplace=True\nprint('Double check the name of the columns:')\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating columns\n\nLet's add a column in which tell us the day of the week using the datetime function day_name(), and another column with the number of the day of the week, using the function weekday","metadata":{}},{"cell_type":"code","source":"day_of_week = df['activity_date'].dt.day_name()\ndf['day_of_week'] = day_of_week\ndf['n_day_of_week'] = df['activity_date'].dt.weekday # 0 represents monday, 6 represents sunday","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking empty cells and null values\n\nChecking for null values with the function isna().sum()","metadata":{}},{"cell_type":"code","source":"print('Total number of null values are: ')\nprint(df.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking for duplicate entries using the function duplicated().sum()","metadata":{}},{"cell_type":"code","source":"print('Total number of duplicated values are: ',df.duplicated().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no null values nor duplicated entries","metadata":{}},{"cell_type":"markdown","source":"### Subsetting the data\n\nNow we can select only the columns we will use for our analysis. In this case","metadata":{}},{"cell_type":"code","source":"df = df[['id', 'activity_date', 'total_steps', 'total_distance',\n       #'tracker_distance', 'logged_activities_distance',\n       #'very_active_distance', 'moderately_active_distance',\n       #'light_active_distance', 'sedentary_active_distance',\n       'very_active_minutes', 'fairly_active_minutes',\n       'lightly_active_minutes', 'sedentary_minutes', 'calories',\n       #'sum_distance','totalminutes', \n       'day_of_week', 'n_day_of_week'\n        ]].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Category creation\n\nNow I'm going to create my own categorization of the users, by level of physical activity and device usage\n\nphysical activity would follow these arguments:\n* Sedentary: less than 6000 daily steps on average\n* Active:  between 6000 and 12000 daily steps on average\n* Very active: more than 12000 daily steps on average\n\nDevice usage will follow these arguments:\n* Low use: less than 8 hours of use per day.\n* Normal use: between 8 and 16 hours of use per day.\n* High use: more than 16 hours of use per day.\n","metadata":{}},{"cell_type":"markdown","source":"For this dataset, I'll only begin by creating the category 'activity_level'.\nI will create the other category when I analize a dataset which has data stored in an hourly basis","metadata":{}},{"cell_type":"code","source":"# I first group the data by the id\nid_grp = df.groupby(['id'])\n\n# Then I look for the average amount of steps, and sort the results in descending order\nid_avg_step = id_grp['total_steps'].mean().sort_values(ascending=False)\n\n# After that, I turn the results into a dataframe\nid_avg_step = id_avg_step.to_frame()\n\n# I want to create a new column which tells in which category each user fits into, depending on the average amount of steps\nconditions = [\n    (id_avg_step <=6000),\n    (id_avg_step > 6000) & (id_avg_step < 12000),\n    (id_avg_step >= 12000)\n] # These are the conditions\n\nvalues = ['sedentary','active','very_active'] # And here are the name of the values\n\n# I create a column with the numpy function, np.select to asign each id a category\nid_avg_step['activity_level'] = np.select(conditions,values)\n\n# I store the results in a variable to use it in the next step\nid_activity_level = id_avg_step['activity_level']\n\n# I use a list comprehension to create the column in our original dataset.\n# With this list comprehension I retrieve the categories where the index match the id column\ndf['activity_level'] = [id_activity_level[c] for c in df['id']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Analyze","metadata":{}},{"cell_type":"markdown","source":"Let's check how many unique id's there are with the function nunique().\nAnd what are those with the unique() function","metadata":{}},{"cell_type":"code","source":"print('Number of unique values in id column:',df['id'].nunique())\nprint()\nprint('List of id values:',df['id'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and now let's see how much they appear in the dataset with value_counts()","metadata":{}},{"cell_type":"code","source":"print('How many times each id appear in the dataset?')\nprint(df['id'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, there are 33 unique id's or users, and most appear 31 times throughout the dataset, some less than that","metadata":{}},{"cell_type":"markdown","source":"Now let's check the date column, what is the minimum date, maximum date, the days between them, and number of unique dates","metadata":{}},{"cell_type":"code","source":"print('The min date is:',min(df['activity_date']))\nprint('The max date is:',max(df['activity_date']))\nprint('The number of unique dates are:',df['activity_date'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we have exactly 31 days, ranging from '2016-04-12' to '2016-05-12'","metadata":{}},{"cell_type":"markdown","source":"Now we can start making an exploratory data analysis","metadata":{}},{"cell_type":"code","source":"# First we use the describe() function to see some statistics\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T20:07:56.160604Z","iopub.execute_input":"2023-09-18T20:07:56.161547Z","iopub.status.idle":"2023-09-18T20:07:56.196419Z","shell.execute_reply.started":"2023-09-18T20:07:56.161477Z","shell.execute_reply":"2023-09-18T20:07:56.195529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see the mean or average, the min and max values. the 50% median, etc..\n\nWe can already see in the max row that someone walked for 28 miles and someone burned 4900 calories, it could be an outlier so we may pay attention to it later","metadata":{}},{"cell_type":"markdown","source":"# Step 5.- Share ","metadata":{}},{"cell_type":"markdown","source":"## Correlation between calories steps and calories\n\nWhat is the correlation between the amount of steps done, and the amount of calories burnt?","metadata":{}},{"cell_type":"code","source":"ax =sns.scatterplot(x='total_steps', y='calories', data=df,hue='activity_level')\n\n#handles, labels = ax.get_legend_handles_labels()\n#plt.legend(handles, day_of_week, fontsize=7)\nplt.title('Correlation Calories vs. Steps')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:14:46.581119Z","iopub.execute_input":"2023-09-18T21:14:46.581746Z","iopub.status.idle":"2023-09-18T21:14:47.021505Z","shell.execute_reply.started":"2023-09-18T21:14:46.581683Z","shell.execute_reply":"2023-09-18T21:14:47.020096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see in this scatterplot a somewhat positive correlation, the more steps done, the more calories burnt.\nAlso we divided the dots by colors, using the activity_level category, so we can see which group is representing the data shown","metadata":{}},{"cell_type":"markdown","source":"## Average number of steps per day\n\nWhat is the average number of steps per day?","metadata":{}},{"cell_type":"code","source":"day_of_week = ['Monday','Tuesday','Wednesday','Thursday', 'Friday','Saturday','Sunday']\nfig, ax =plt.subplots(1,1,figsize=(9,6))\n\nday_grp = df.groupby(['day_of_week'])\navg_daily_steps= day_grp['total_steps'].mean()\navg_steps = df['total_steps'].mean()\n\nplt.bar(avg_daily_steps.index,avg_daily_steps)\n\nax.set_xticks(range(len(day_of_week)))\nax.set_xticklabels(day_of_week)\n\nax.axhline(y=avg_daily_steps.mean(),color='red', label='Average daily steps')\nax.set_ylabel('Number of steps')\nax.set_xlabel('Day of the week')\nax.set_title('Avg Number of steps per day')\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:14:49.814221Z","iopub.execute_input":"2023-09-18T21:14:49.814696Z","iopub.status.idle":"2023-09-18T21:14:50.038385Z","shell.execute_reply.started":"2023-09-18T21:14:49.814652Z","shell.execute_reply":"2023-09-18T21:14:50.037421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results show that Monday, Tuesday and Saturday are the days where the users were more physically active and above the average numbert of steps overall.\nWednesday, Thursday, and Friday are below the average but the three fell into the same area.\nSunday is the least active of all the weekdays.\n\nWith this information we can interpret that users tend to be more physically active during the firsts days of the week and during saturdays, giving us a hint of the activities they may do.","metadata":{}},{"cell_type":"markdown","source":"## Percentage of activity in minutes\n\nWhat percentage of the time are people active?","metadata":{}},{"cell_type":"code","source":"very_active_mins = df['very_active_minutes'].sum() \nfairly_active_mins = df['fairly_active_minutes'].sum()\nlightly_active_mins = df['lightly_active_minutes'].sum()\nsedentary_mins = df['sedentary_minutes'].sum()\n\nslices = [very_active_mins,fairly_active_mins,lightly_active_mins,sedentary_mins]\nlabels = ['very active minutes','fairly active minutes','lightly active minutes','sedentary minutes']\nexplode = [0,0,0,0.1]\nplt.pie(slices, labels = labels, explode = explode, autopct='%1.1f%%',textprops=dict(size=9), shadow=True)\n\nplt.title('Percentage of activity in minutes',fontsize=18)\nplt.tight_layout()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:14:53.867155Z","iopub.execute_input":"2023-09-18T21:14:53.867593Z","iopub.status.idle":"2023-09-18T21:14:54.065710Z","shell.execute_reply.started":"2023-09-18T21:14:53.867545Z","shell.execute_reply":"2023-09-18T21:14:54.064679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This pie chart shows that the users are in a sedentary state of activity most of the time, a sixth of the time doing light activity and only 2% of the time being active doing proper excercise.","metadata":{}},{"cell_type":"markdown","source":"## Correlation Between activity level minutes and calories","metadata":{}},{"cell_type":"code","source":"n_day_of_week = [0,1,2,3,4,5,6]\n\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(11,15),dpi=70)\n\nsns.scatterplot(data=df,x='calories',y='sedentary_minutes',hue='activity_level',ax=axes[0,0],legend=False)\n\nsns.scatterplot(data=df,x='calories',y='lightly_active_minutes',hue='activity_level',ax=axes[0,1],legend=False)\n\nsns.scatterplot(data=df,x='calories',y='fairly_active_minutes',hue='activity_level',ax=axes[1,0],legend=False)\n\nsns.scatterplot(data=df,x='calories',y='very_active_minutes',hue='activity_level',ax=axes[1,1])\n\n\nplt.legend(title='Activity level',title_fontsize=20,bbox_to_anchor=(1.8,2.2),fontsize=18,frameon=True,scatterpoints=1)\nfig.suptitle('Correlation Between activity level minutes and calories',x=0.5,y=0.92,fontsize=24)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6.- Act","metadata":{}},{"cell_type":"markdown","source":"After\nanalyzing FitBit Fitness Tracker Data,\nwe have found some insights that would\nhelp influence Bellabeat marketing strategy","metadata":{}},{"cell_type":"markdown","source":"## A multipurpose device\n\nBellabeat\ncan let know users, that their products are not\nonly meant for sports, or excersice related activities As\nthe data show, many users spend more time wearing\nthe tracking device on weekends than on weekdays, this\ncould mean that they relate the product just to sports\nor for only the usual walking to the park on sundays\nBellabeat can show that their products are meant to\nacompany them wherever they go for any daily\nactivities, such as work And help them track\ninformation to improve overall fitness and health This\nwill encourage women from diverse demographic\nfeatures and backgrounds to use Bellabeat's product\nmeant for all women who care about overall health","metadata":{}},{"cell_type":"markdown","source":"## Rewards and reminds\nBellabeat\ncan integrate functions within the bellabeat\napp or other products, such as rewards or incentives,\nand reminds to encourage their users to hit certain\nmarks These marks could be achieving the minimum\namount of 7 500 steps per day, certain calorie burning\nfor people who want to lose weight, or the 8 hour sleep\npattern Certain rewards could be showing a\nleaderboard of top users who have reached and\nmaintained the minimum steps a day for longer, virtual\nmedals or prizes, such as discounts or offers For the\nreminds part, Bellabeat could send notifications to their\nusers when they are lagging behind in such goals, and\nalso it could offer recomendations to their users to help\nthem with their sleep, or achieving their goals","metadata":{}}]}